{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Complete process of determining words that are related to dataset and database search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.110321Z",
     "end_time": "2023-08-14T16:02:07.286316Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Tokenizer\n",
    "#### same tokenizer used for both models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "def Initialize_tokenizer():\n",
    "    from transformers import DistilBertTokenizerFast\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "    return tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.121566Z",
     "end_time": "2023-08-14T16:02:07.290653Z"
    }
   },
   "id": "5c0e14261671efe8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Token Classification Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "def Token_Classification_Initialization():\n",
    "    from transformers import DistilBertForTokenClassification\n",
    "    Token_Classification_Labels = {\n",
    "                                  'O': 0,\n",
    "                                  'B-Product': 1,\n",
    "                                  'I-Product': 2,\n",
    "                                  'B-Material': 3,\n",
    "                                  'I-Material': 4,\n",
    "                                  'B-Country': 5,\n",
    "                                  'I-Country': 6,\n",
    "                                  'B-Application': 7,\n",
    "                                  'I-Application': 8,\n",
    "                                  'B-Recycle': 9,\n",
    "                                  'I-Recycle': 10\n",
    "                                  }\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    Token_Classification_model = DistilBertForTokenClassification.from_pretrained(\n",
    "                                    'distilbert-base-uncased',\n",
    "                                    num_labels=len(Token_Classification_Labels)\n",
    "                                                                                ).to(device)\n",
    "    return Token_Classification_Labels, Token_Classification_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.132495Z",
     "end_time": "2023-08-14T16:02:07.437978Z"
    }
   },
   "id": "e606a72f6e6501ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Takes list of sentences as input, along with labels, model, tokenizer, and token classification load file location"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "def Token_Classification_Results(List_of_Sentences: list,\n",
    "                                 Token_Classification_Labels: dict,\n",
    "                                 Token_Classification_model,\n",
    "                                 tokenizer,\n",
    "                                 Token_Class_File: str\n",
    "                                 ) -> dict:\n",
    "    # Puts model into eval mode\n",
    "    Token_Classification_model.eval()\n",
    "\n",
    "    # Loads the saved file of Pre-trained model\n",
    "    Token_Classification_model.load_state_dict(torch.load(Token_Class_File))\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Inverse mapping from label indices to labels\n",
    "    inv_label_map = {v: k for k, v in Token_Classification_Labels.items()}\n",
    "\n",
    "    # Creating Final Dictionary for results\n",
    "    final_dict = {\n",
    "                  'Product Type': [],\n",
    "                  'Material Type': [],\n",
    "                  'Building applications': [],\n",
    "                  'Countries': [],\n",
    "                  'Recycled Content': []\n",
    "                  }\n",
    "    \n",
    "    \n",
    "    # Cycling through query\n",
    "    for sentence in List_of_Sentences:\n",
    "        # Encode the sentence\n",
    "        inputs = tokenizer.encode_plus(\n",
    "                                        sentence,\n",
    "                                        None,\n",
    "                                        add_special_tokens=True,\n",
    "                                        padding='longest',\n",
    "                                        return_token_type_ids=True\n",
    "                                        )\n",
    "\n",
    "        # Create torch tensors and move them to the device\n",
    "        input_ids = torch.tensor([inputs['input_ids']], dtype=torch.long).to(device)\n",
    "        attention_mask = torch.tensor([inputs['attention_mask']], dtype=torch.long).to(device)\n",
    "\n",
    "        # Run the sentence through the model\n",
    "        with torch.no_grad():\n",
    "            outputs = Token_Classification_model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get the token-level class probabilities\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Compute the predicted labels\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Remove padding and special tokens\n",
    "        input_ids = input_ids[0].tolist()\n",
    "        predictions = predictions[0].tolist()\n",
    "\n",
    "        real_predictions = [pred for id, pred in zip(input_ids, predictions) if id != 0 and id != 101 and id != 102]\n",
    "\n",
    "        # Map predicted label indices back to label strings\n",
    "        predicted_labels = [inv_label_map[label] for label in real_predictions]\n",
    "\n",
    "        # Combine tokens and their predicted labels into dict\n",
    "        results = dict(zip(sentence.split(' '), predicted_labels))\n",
    "\n",
    "        # Put results into final_dict, key is word and value is what it is labeled as\n",
    "        for word, label in results.items():\n",
    "            print(word, label)\n",
    "            if word in ['for', 'and', 'from', 'in']:\n",
    "                continue\n",
    "            if label != 'O':\n",
    "                # Adds word to proper dictionary if belongs to that type\n",
    "\n",
    "                # Checks if there is a B-word before the I-word so it will add to it\n",
    "\n",
    "                # It will make a new word if there is no B-word\n",
    "\n",
    "                if label == 'B-Product':\n",
    "                    final_dict['Product Type'].append(word)\n",
    "\n",
    "                elif label == 'I-Product':\n",
    "\n",
    "                  if final_dict['Product Type']:\n",
    "                    final_dict['Product Type'][-1] += ' ' + word\n",
    "                  else:\n",
    "                    final_dict['Product Type'].append(word)\n",
    "\n",
    "                elif label == 'B-Material':\n",
    "                    final_dict['Material Type'].append(word)\n",
    "\n",
    "                elif label == 'I-Material':\n",
    "\n",
    "                  if final_dict['Material Type']:\n",
    "                    final_dict['Material Type'][-1] += ' ' + word\n",
    "                  else:\n",
    "                     final_dict['Material Type'].append(word)\n",
    "\n",
    "                elif label == 'B-Country':\n",
    "                    final_dict['Countries'].append(word)\n",
    "\n",
    "                elif label == 'I-Country':\n",
    "\n",
    "                  if final_dict['Countries']:\n",
    "                    final_dict['Countries'][-1] += ' ' + word\n",
    "                  else:\n",
    "                    final_dict['Countries'].append(word)\n",
    "\n",
    "                elif label == 'B-Application':\n",
    "                    final_dict['Building applications'].append(word)\n",
    "\n",
    "                elif label == 'I-Application':\n",
    "\n",
    "                  if final_dict['Building applications']:\n",
    "                    final_dict['Building applications'][-1] += ' ' + word\n",
    "                  else:\n",
    "                    final_dict['Building applications'].append(word)\n",
    "\n",
    "                elif label == 'B-Recycle':\n",
    "                    final_dict['Recycled Content'].append(word)\n",
    "\n",
    "                elif label == 'I-Recycle':\n",
    "\n",
    "                    if final_dict['Recycled Content']:\n",
    "                        final_dict['Recycled Content'][-1] += ' ' + word\n",
    "                    else:\n",
    "                        final_dict['Recycled Content'].append(word)\n",
    "        print('\\n')\n",
    "\n",
    "\n",
    "    return final_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.133467Z",
     "end_time": "2023-08-14T16:02:07.440912Z"
    }
   },
   "id": "9cc17742fc549e55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Label Encoder function to process labels for Sequence Classification model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "def label_encoder_initialization(sheet_name: str):\n",
    "    '''\n",
    "    LABEL ENCODER EXCEL FILE\n",
    "    Layout: one column per sheet, column_name = 'labels'\n",
    "    sheet_name = corresponding sheet with labels used for Sequence Classification Model\n",
    "    WHEN CREATING TRAINING DATA SAVE LABELS INTO EXCEL OR CSV FILE FOR THIS PROCESS\n",
    "    '''\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    df = pd.read_excel('YOUR_EXCEL_FILE.xlsx, (CAN ALSO BE .csv FILE)', sheet_name=sheet_name)\n",
    "    labels = df['labels'].tolist()\n",
    "    le = LabelEncoder()\n",
    "    le.fit_transform(labels)\n",
    "    return le"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.160589Z",
     "end_time": "2023-08-14T16:02:07.440912Z"
    }
   },
   "id": "ed3160033ef73269"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize Sequence Classification model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "def Sequence_Classification_Model_Initialization(le):\n",
    "    from transformers import DistilBertForSequenceClassification\n",
    "    Sequence_Classification_Model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(le.classes_))\n",
    "    return Sequence_Classification_Model, le"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.164269Z",
     "end_time": "2023-08-14T16:02:07.440912Z"
    }
   },
   "id": "4c15ab6f59f55f22"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Function to create tokenizer and token classification labels and model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "def NER_initialization():\n",
    "    tokenizer = Initialize_tokenizer()\n",
    "    Token_Classification_Labels, Token_Classification_model = Token_Classification_Initialization()\n",
    "    return tokenizer, Token_Classification_Labels, Token_Classification_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.174237Z",
     "end_time": "2023-08-14T16:02:07.440912Z"
    }
   },
   "id": "8549ae9831163edc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Function to create sequence classification model and label encoder variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "def Category_initialization(sheet_name: str):\n",
    "    Seq_model, le = Sequence_Classification_Model_Initialization(label_encoder_initialization(sheet_name=sheet_name))\n",
    "    return Seq_model, le"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.183372Z",
     "end_time": "2023-08-14T16:02:07.440912Z"
    }
   },
   "id": "8e99e8fb12247a4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Category Matching prediction, for sequence classification model\n",
    "### Intakes words from NERModel, Sequence classification model, same tokenizer from before, label encoder, and file location of trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "def Category_Matching_Prediction(input_words, Sequence_Classification_Model, tokenizer, le, Sequence_Class_File):\n",
    "    Sequence_Classification_Model.eval()\n",
    "    Sequence_Classification_Model.load_state_dict(torch.load(Sequence_Class_File, map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    final_output = []\n",
    "\n",
    "    for word in input_words:\n",
    "        word = word.lower()\n",
    "\n",
    "        input_text_encoded = tokenizer(word, truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = Sequence_Classification_Model(**input_text_encoded).logits\n",
    "\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        top_5_probs, top_5_labels = torch.topk(probs, 5)\n",
    "\n",
    "        top_5_labels = le.inverse_transform(top_5_labels.cpu().detach().numpy()[0])\n",
    "        top_5_probs = top_5_probs.cpu().detach().numpy()[0]\n",
    "\n",
    "        predicted_product_types = list(top_5_labels)\n",
    "        predicted_probabilities = list(top_5_probs)\n",
    "\n",
    "        predicted_probabilities = [p / sum(predicted_probabilities) for p in predicted_probabilities]\n",
    "\n",
    "        for pt, prob in zip(predicted_product_types, predicted_probabilities):\n",
    "            final_output.append((pt, round(prob * 100, 2)))\n",
    "    return final_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.196992Z",
     "end_time": "2023-08-14T16:02:07.440912Z"
    }
   },
   "id": "3958404160576d34"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Function to find the recycled content if there is any present in the original query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "def find_recycled_content(input_string):\n",
    "    import re\n",
    "    # Load an excel sheet containing recycled content categories and their respective keywords into a DataFrame\n",
    "    '''\n",
    "    REPLACE TEXT WITH CORRESPONDING EXCEL FILE WITH RECYCLED CONTENT SHEET\n",
    "    EXCEL FILE PROPEIETARY KNOWLEDGE OF 2050 MATERIALS,\n",
    "    CONTACT info@2050-materials.com FOR MORE INFORMATION\n",
    "    '''\n",
    "    df = pd.read_excel('EXCEL_FILE_REDACTED', sheet_name='recycled_content')\n",
    "    \n",
    "    # Compute the length of the 'keywords' for each category\n",
    "    df['keywords_len'] = df['keywords'].apply(len)\n",
    "    # Sort the dataframe based on the length of 'keywords' in descending order\n",
    "    # This ensures that longer and more specific keywords are matched first\n",
    "    df = df.sort_values('keywords_len', ascending=False)\n",
    "\n",
    "    # Remove the auxiliary 'keywords_len' column\n",
    "    df = df.drop(columns=['keywords_len'])\n",
    "    # Normalize the input string: remove extra spaces and convert to lowercase\n",
    "    input_string = re.sub(' +', ' ', input_string.lower())\n",
    "\n",
    "    direct_num_match = re.search(r'([>≈]\\s*\\d+(\\.\\d+)?%)', input_string)\n",
    "    if direct_num_match:\n",
    "        return direct_num_match.group()\n",
    "\n",
    "    # If the input contains a percentage (no other words)\n",
    "    simple_percentage_match = re.match(r'\\d+(\\.\\d+)?%', input_string)\n",
    "    if simple_percentage_match:\n",
    "        found_percentage = simple_percentage_match.group()\n",
    "        other_keywords_present = any(keyword in input_string for keyword in df['keywords'].str.lower())\n",
    "        if not other_keywords_present:\n",
    "            return found_percentage\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        recycled_content = str(row['recycled_content']).lower()\n",
    "        if recycled_content in input_string:\n",
    "            return recycled_content\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        keywords = row['keywords'].lower().split(',')\n",
    "        for keyword in keywords:\n",
    "            keyword = keyword.strip()\n",
    "\n",
    "            if 'x' in keyword:\n",
    "                if '.x' in keyword:\n",
    "                    num_pattern = r'(0\\.\\d+|\\.\\d+|\\d+)'\n",
    "                else:\n",
    "                    num_pattern = r'\\d+'\n",
    "                keyword_x_replaced = keyword.replace('.x', num_pattern)\n",
    "                match = re.search(keyword_x_replaced, input_string)\n",
    "\n",
    "                if match:\n",
    "                    num_str = match.group()\n",
    "                    num_match = re.search(r'\\b0\\.\\d+\\b|\\.\\d+|\\b\\d+\\b', num_str)\n",
    "                    if num_match:\n",
    "                        num_str = num_match.group()\n",
    "                        if '.' in num_str and not num_str.startswith('0'):\n",
    "                            num_str = '0' + num_str\n",
    "                        num = float(num_str)\n",
    "                        if '.' in num_str:\n",
    "                            num *= 100\n",
    "                    return row['recycled_content'].replace('x', str(num))\n",
    "\n",
    "            if keyword in input_string:\n",
    "                return row['recycled_content']\n",
    "\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.208171Z",
     "end_time": "2023-08-14T16:02:07.455823Z"
    }
   },
   "id": "a7bec7f9c0497958"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper function with recycle content to take results from above function and turn number into float and determine if greater than or equal to"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "def recycle_content_process(value):\n",
    "    if '>' in value:\n",
    "        val = '>'\n",
    "        num = float(value[2:-1])\n",
    "    elif '≈' in value:\n",
    "        val = '='\n",
    "        num = float(value[2:-1])\n",
    "    else:\n",
    "        val = 'x'\n",
    "        num = float(value[:-1])\n",
    "    return [val, num]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.210644Z",
     "end_time": "2023-08-14T16:02:07.455823Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processes all functions into one function, intaking the ['customer query in this format']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "def complete_model_results(list_of_queries):\n",
    "    tokenizer, Token_Classification_Labels, Token_Classification_model = NER_initialization()\n",
    "    '''\n",
    "    TOKEN CLASSIFICATION MODEL .pth FILE LOCATION\n",
    "    '''\n",
    "    model_file = 'YOUR_TOKEN_CLASSIFICATION_MODEL.pth'\n",
    "\n",
    "    NER_output = Token_Classification_Results(List_of_Sentences=list_of_queries,\n",
    "                                            Token_Classification_Labels=Token_Classification_Labels,\n",
    "                                            Token_Classification_model=Token_Classification_model,\n",
    "                                            tokenizer=tokenizer,\n",
    "                                            Token_Class_File=model_file\n",
    "                                            )\n",
    "    '''\n",
    "    .pth FILES IN NEXT SECTION ARE ALL THE SAVED MODELS TRAINED WITH SEQUENCE CLASSIFICATION MODEL\n",
    "    LOAD EACH MODEL INDIVIDUAL FILE LOCATION DEPENDING ON OUTPUT FROM TOKEN CLASSIFICATION MODEL\n",
    "    '''\n",
    "    if NER_output['Product Type']:\n",
    "        Seq_model, le = Category_initialization('product_types')\n",
    "        Seq_Class_file = 'SEQUENCE_CLASSIFICATION_MODEL_FILE.pth'\n",
    "\n",
    "        p_type = Category_Matching_Prediction(NER_output['Product Type'],\n",
    "                 Seq_model,\n",
    "                 tokenizer=tokenizer,\n",
    "                 le=le,\n",
    "                 Sequence_Class_File=Seq_Class_file\n",
    "                     )\n",
    "        NER_output['Product Type'] = p_type\n",
    "\n",
    "    if NER_output['Material Type']:\n",
    "        Seq_model, le = Category_initialization('material_types')\n",
    "        Seq_Class_file = 'SEQUENCE_CLASSIFICATION_MODEL_FILE.pth'\n",
    "\n",
    "        m_type = Category_Matching_Prediction(NER_output['Material Type'],\n",
    "                 Seq_model,\n",
    "                 tokenizer=tokenizer,\n",
    "                 le=le,\n",
    "                 Sequence_Class_File=Seq_Class_file\n",
    "                     )\n",
    "        NER_output['Material Type'] = m_type\n",
    "\n",
    "    if NER_output['Building applications']:\n",
    "        Seq_model, le = Category_initialization('building_application')\n",
    "        Seq_Class_file = 'SEQUENCE_CLASSIFICATION_MODEL_FILE.pth'\n",
    "\n",
    "        ba_type = Category_Matching_Prediction(NER_output['Building applications'],\n",
    "                 Seq_model,\n",
    "                 tokenizer=tokenizer,\n",
    "                 le=le,\n",
    "                 Sequence_Class_File=Seq_Class_file\n",
    "                     )\n",
    "        NER_output['Building applications'] = ba_type\n",
    "\n",
    "    if NER_output['Recycled Content']:\n",
    "        if len(NER_output['Recycled Content']) > 1:\n",
    "            NER_output['Recycled Content'] = [' '.join(NER_output['Recycled Content'])]\n",
    "        NER_output['Recycled Content'] = find_recycled_content(NER_output['Recycled Content'][0])\n",
    "\n",
    "    return NER_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.223903Z",
     "end_time": "2023-08-14T16:02:07.455823Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATABASE SEARCH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This function looks for the top result (per category) out of all the results in the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "def database_search_top1(final_dict):\n",
    "    '''\n",
    "    DATASET REDACTED, PROPRIETARY INFORMATION OF 2050 MATERIALS,\n",
    "    CONTACT info@2050-materials.com FOR MORE INFORMATION\n",
    "    :return: displays info from dataset of products from 2050 Materials\n",
    "    '''\n",
    "    df = pd.read_csv('FILE REDACTED')\n",
    "\n",
    "    df['recycled_content'].fillna(0.0, inplace=True)\n",
    "    if final_dict['Product Type']:\n",
    "        words = [word[0] for word in final_dict['Product Type']]\n",
    "        df = df.loc[df['product_type'].str.lower().isin([words[0]])]\n",
    "    if final_dict['Material Type']:\n",
    "        words = [word[0] for word in final_dict['Material Type']]\n",
    "        df = df.loc[df['material_types'].str.lower().isin([words[0]])]\n",
    "    if final_dict['Building applications']:\n",
    "        words = [word[0] for word in final_dict['Building applications']]\n",
    "        df = df.loc[df['building_application'].str.lower().isin([words[0]])]\n",
    "    if final_dict['Countries']:\n",
    "        df = df.loc[df['country'].str.lower().isin(final_dict['Countries'])]\n",
    "    if final_dict['Recycled Content']:\n",
    "        val, num = recycle_content_process(final_dict['Recycled Content'])\n",
    "        if val in ['>', 'x']:\n",
    "            df = df.loc[df['recycled_content'] > num]\n",
    "        elif val == '=':\n",
    "            df = df.loc[df['recycled_content'] == num]\n",
    "    return df[['name', 'product_type', 'material_types', 'building_application', 'country', 'recycled_content']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.239217Z",
     "end_time": "2023-08-14T16:02:07.455823Z"
    }
   },
   "id": "d0f2154f23fb4a32"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This function looks for all the results from the query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "def database_search_top5(final_dict):\n",
    "    '''\n",
    "    DATASET REDACTED, PROPRIETARY INFORMATION OF 2050 MATERIALS,\n",
    "    CONTACT info@2050-materials.com FOR MORE INFORMATION\n",
    "    :return: displays info from dataset of products from 2050 Materials\n",
    "    '''\n",
    "    df = pd.read_csv('FILE REDACTED')\n",
    "\n",
    "    df['recycled_content'].fillna(0.0, inplace=True)\n",
    "    if final_dict['Product Type']:\n",
    "        words = [word[0] for word in final_dict['Product Type']]\n",
    "        df = df.loc[df['product_type'].str.lower().isin(words)]\n",
    "    if final_dict['Material Type']:\n",
    "        words = [word[0] for word in final_dict['Material Type']]\n",
    "        df = df.loc[df['material_types'].str.lower().isin(words)]\n",
    "    if final_dict['Building applications']:\n",
    "        words = [word[0] for word in final_dict['Building applications']]\n",
    "        df = df.loc[df['building_application'].str.lower().isin(words)]\n",
    "    if final_dict['Countries']:\n",
    "        df = df.loc[df['country'].str.lower().isin(final_dict['Countries'])]\n",
    "    if final_dict['Recycled Content']:\n",
    "        val, num = recycle_content_process(final_dict['Recycled Content'])\n",
    "        if val in ['>', 'x']:\n",
    "            df = df.loc[df['recycled_content'] > num]\n",
    "        elif val == '=':\n",
    "            df = df.loc[df['recycled_content'] == num]\n",
    "    return df[['name', 'product_type', 'material_types', 'building_application', 'country', 'recycled_content']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.249771Z",
     "end_time": "2023-08-14T16:02:07.455823Z"
    }
   },
   "id": "f23cf8a1beb3c0a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test below with any query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sand B-Product\n",
      "with O\n",
      "50% I-Recycle\n",
      "recycle O\n",
      "content O\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Product Type': [('aggregates', 95.85),\n  ('in situ', 2.13),\n  ('binder', 0.69),\n  ('foundation solution', 0.67),\n  ('formwork', 0.67)],\n 'Material Type': [],\n 'Building applications': [],\n 'Countries': [],\n 'Recycled Content': '50%'}"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict = complete_model_results(['sand with 50% recycle content'])\n",
    "final_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:07.256031Z",
     "end_time": "2023-08-14T16:02:09.373758Z"
    }
   },
   "id": "c4650a247affa263"
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Product Type', [('aggregates', 95.85), ('in situ', 2.13), ('binder', 0.69), ('foundation solution', 0.67), ('formwork', 0.67)])\n",
      "('Material Type', [])\n",
      "('Building applications', [])\n",
      "('Countries', [])\n",
      "('Recycled Content', '50%')\n"
     ]
    }
   ],
   "source": [
    "for item in final_dict.items():\n",
    "    print(item)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:09.371798Z",
     "end_time": "2023-08-14T16:02:09.374267Z"
    }
   },
   "id": "c6d25a0e337dab28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## View the results from database"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "# RESULTS REDACTED"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T16:02:09.544806Z",
     "end_time": "2023-08-14T16:02:09.592174Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
